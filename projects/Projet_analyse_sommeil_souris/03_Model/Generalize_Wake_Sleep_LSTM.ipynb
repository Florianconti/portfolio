{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import GRU, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "spec = importlib.util.spec_from_file_location(\"preprocessing\", \"..\\\\utils\\\\preprocessing.py\")\n",
    "preprocessing = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(preprocessing)\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"fspliter\", \"..\\\\utils\\\\files_spliter.py\")\n",
    "fspliter = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(fspliter)\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"results\", \"..\\\\utils\\\\results.py\")\n",
    "results = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(results)\n",
    "\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_test_validation_split_on_day_3(num_mice):\n",
    "\n",
    "    # Loading day 3 without first 6 hours\n",
    "    data = fspliter.get_mice(num_mice)\n",
    "    day3 = fspliter.retrieve_day(data, 3)\n",
    "    day3_without_first_6_hours = day3.iloc[5400:]\n",
    "\n",
    "    # preprocessing and encoding\n",
    "    data_processed = preprocessing.do_preprocessing(day3_without_first_6_hours, 'WS')\n",
    "    data_processed['state_encoded'] = label_encoder.fit_transform(data_processed['state'])\n",
    "\n",
    "    # Feature selection\n",
    "    feature_columns = data_processed.columns[1:-2]\n",
    "\n",
    "    # Scaling\n",
    "    data_processed[feature_columns] = StandardScaler().fit_transform(data_processed[feature_columns])\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components=50)\n",
    "    pca = pca.fit_transform(data_processed[feature_columns])\n",
    "\n",
    "    # Train test val split\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(pca, data_processed['state_encoded'], test_size=0.3, shuffle = False, stratify = None)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle = False, stratify = None)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = train_test_validation_split_on_day_3(9)\n",
    "print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sequence_size = 10\n",
    "\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(100, return_sequences=True, input_shape=(sequence_size, X_train.shape[1]))),\n",
    "    Dropout(0.3),\n",
    "    Bidirectional(LSTM(100)),\n",
    "    Dropout(0.3),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_bidirectional_sequences(data, n):\n",
    "    sequences = []\n",
    "    data_length = len(data)\n",
    "\n",
    "    for i in range(n, data_length - n):\n",
    "        seq = data[i - n: i + n + 1]\n",
    "        sequences.append(seq)\n",
    "\n",
    "    return np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "X_train_sequences = create_bidirectional_sequences(X_train, sequence_size)\n",
    "X_val_sequences = create_bidirectional_sequences(X_val, sequence_size)\n",
    "\n",
    "y_train_adjusted = y_train[sequence_size*2:]\n",
    "y_val_adjusted = y_val[sequence_size*2:]\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(class_weight = \"balanced\", classes= np.unique(y_train_adjusted), y= y_train_adjusted)\n",
    "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "history = model.fit(X_train_sequences, y_train_adjusted, epochs=2, batch_size=64, validation_data=(X_val_sequences, y_val_adjusted), verbose=1, class_weight=class_weights_dict)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.save('Saved_model/Generalize_Wake_Sleep_classification.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Training and validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extracting accuracy and loss from the history object\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# Plotting training and validation accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'bo-', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'ro-', label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting training and validation loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'bo-', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'ro-', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load model if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model = load_model('Saved_model/Mouse_3_state_classification.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_sequences = create_bidirectional_sequences(X_test, sequence_size)\n",
    "\n",
    "y_test_adjusted = y_test[sequence_size*2:]\n",
    "\n",
    "X_test_pred = model.predict(X_test_sequences)\n",
    "\n",
    "predicted_labels = X_test_pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_original = label_encoder.inverse_transform(y_test_adjusted)\n",
    "y_pred_original = label_encoder.inverse_transform(predicted_labels)\n",
    "\n",
    "results.scores(y_test_original, y_pred_original, ('W', 'S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Testing model on other mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_model_on_other_mice(model, num_mice):\n",
    "    X_testmouse, _, _, y_testmouse, _, _ = train_test_validation_split_on_day_3(num_mice)\n",
    "\n",
    "    X_test_sequences = create_bidirectional_sequences(X_testmouse, 10)\n",
    "\n",
    "    y_test_adjusted = y_testmouse[20:]\n",
    "\n",
    "    X_test_pred = model.predict(X_test_sequences)\n",
    "    predicted_labels = X_test_pred.argmax(axis=1)\n",
    "    y_test_original = label_encoder.inverse_transform(y_test_adjusted)\n",
    "    y_pred_original = label_encoder.inverse_transform(predicted_labels)\n",
    "    results.scores(y_test_original, y_pred_original, ('W', 'S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Testing model on same strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_model_on_other_mice(model, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Testing model on other strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_model_on_other_mice(model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "arnn",
   "language": "python",
   "display_name": "arnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
