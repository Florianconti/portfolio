{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Importing libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import GRU, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import importlib\n",
    "spec = importlib.util.spec_from_file_location(\"preprocessing\", \"..\\\\utils\\\\preprocessing.py\")\n",
    "preprocessing = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(preprocessing)\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"fspliter\", \"..\\\\utils\\\\files_spliter.py\")\n",
    "fspliter = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(fspliter)\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"results\", \"..\\\\utils\\\\results.py\")\n",
    "results = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(results)\n",
    "\n",
    "label_encoder = LabelEncoder()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_test_validation_split(data):\n",
    "\n",
    "    # preprocessing and encoding\n",
    "    data_processed = preprocessing.do_preprocessing(data)\n",
    "    data_processed['state_encoded'] = label_encoder.fit_transform(data_processed['state'])\n",
    "\n",
    "    # selection of features and scaling\n",
    "    feature_columns = data_processed.columns[1:-2]\n",
    "    bin_columns = [col for col in feature_columns if 'bin' in col]\n",
    "    data_processed[feature_columns] = StandardScaler().fit_transform(data_processed[feature_columns])\n",
    "\n",
    "    # split data into days\n",
    "    day1 = fspliter.retrieve_day(data_processed, 1)\n",
    "    day2 = fspliter.retrieve_day(data_processed, 2)\n",
    "    day3 = fspliter.retrieve_day(data_processed, 3)\n",
    "    day4 = fspliter.retrieve_day(data_processed, 4)\n",
    "\n",
    "    # Concatenate day1 and day2 to form the train set\n",
    "    train_data = pd.concat([day1, day2])\n",
    "\n",
    "    # PCA on bin columns\n",
    "    pca = PCA(n_components=30)\n",
    "    X_train_pca = pca.fit_transform(train_data[bin_columns])\n",
    "    X_val_pca = pca.transform(day4[bin_columns])\n",
    "    X_test_pca = pca.transform(day3[bin_columns])\n",
    "\n",
    "    # Concatenate PCA results with EEGv and EMGv\n",
    "    X_train = pd.concat([train_data[['EEGv', 'EMGv']].reset_index(drop=True),\n",
    "                         pd.DataFrame(X_train_pca)], axis=1)\n",
    "    X_val = pd.concat([day4[['EEGv', 'EMGv']].reset_index(drop=True),\n",
    "                       pd.DataFrame(X_val_pca)], axis=1)\n",
    "    X_test = pd.concat([day3[['EEGv', 'EMGv']].reset_index(drop=True),\n",
    "                        pd.DataFrame(X_test_pca)], axis=1)\n",
    "\n",
    "    # Labels\n",
    "    y_train = train_data['state_encoded']\n",
    "    y_val = day4['state_encoded']\n",
    "    y_test = day3['state_encoded']\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_test_validation_split_on_day_3(data):\n",
    "\n",
    "    day3 = fspliter.retrieve_day(data, 3)\n",
    "    day3_without_first_6_hours = day3.iloc[5400:]\n",
    "\n",
    "    # preprocessing and encoding\n",
    "    data_processed = preprocessing.do_preprocessing(day3_without_first_6_hours)\n",
    "    data_processed['state_encoded'] = label_encoder.fit_transform(data_processed['state'])\n",
    "\n",
    "    # selection of features and scaling\n",
    "    feature_columns = data_processed.columns[1:-2]\n",
    "    bin_columns = [col for col in feature_columns if 'bin' in col]\n",
    "    data_processed[feature_columns] = StandardScaler().fit_transform(data_processed[feature_columns])\n",
    "\n",
    "    # PCA on bin columns\n",
    "    pca = PCA(n_components=30)\n",
    "    pca = pca.fit_transform(data_processed[bin_columns])\n",
    "\n",
    "    # Concatenate PCA results with EEGv and EMGv\n",
    "    df_pca = pd.concat([data_processed[['EEGv', 'EMGv']].reset_index(drop=True),\n",
    "                         pd.DataFrame(pca)], axis=1)\n",
    "\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(df_pca, data_processed['state_encoded'], test_size=0.3, shuffle = False, stratify = None)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle = False, stratify = None)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mouse = fspliter.get_mice(0)\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_test_validation_split_on_day_3(mouse)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Bidirectional(LSTM(100, return_sequences=True, input_shape=(20, X_train.shape[1]))),\n",
    "    Dropout(0.3),\n",
    "    Bidirectional(LSTM(100)),\n",
    "    Dropout(0.3),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(3, activation='softmax')  # 3 output units for 3 classes (w, n, r)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_bidirectional_sequences(data, n):\n",
    "    sequences = []\n",
    "    data_length = len(data)\n",
    "\n",
    "    for i in range(n, data_length - n):\n",
    "        seq = data[i - n: i + n + 1]\n",
    "        sequences.append(seq)\n",
    "\n",
    "    return np.array(sequences)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_sequences(data, sequence_length):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        sequences.append(data[i:i + sequence_length])\n",
    "    return np.array(sequences)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "X_train_array = X_train.values\n",
    "X_val_array = X_val.values\n",
    "\n",
    "#X_train_sequences = create_sequences(X_train.values, 10)\n",
    "#X_val_sequences = create_sequences(X_val.values, 10)\n",
    "\n",
    "X_train_sequences = create_bidirectional_sequences(X_train.values, 10)\n",
    "X_val_sequences = create_bidirectional_sequences(X_val.values, 10)\n",
    "\n",
    "y_train_adjusted = y_train[20:]\n",
    "y_val_adjusted = y_val[20:]\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(class_weight = \"balanced\", classes= np.unique(y_train_adjusted), y= y_train_adjusted)\n",
    "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "history = model.fit(X_train_sequences, y_train_adjusted, epochs=2, batch_size=64, validation_data=(X_val_sequences, y_val_adjusted), verbose=1, class_weight=class_weights_dict)\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Saving model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#model.save('Saved_model/Mouse_3_state_classification.h5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training and validation results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extracting accuracy and loss from the history object\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# Plotting training and validation accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'bo-', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'ro-', label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting training and validation loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'bo-', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'ro-', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load model if needed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#model = load_model('Saved_model/Mouse_3_state_classification.h5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#X_test_sequences = create_sequences(X_test.values, 10)\n",
    "X_test_sequences = create_bidirectional_sequences(X_test.values, 10)\n",
    "\n",
    "y_test_adjusted = y_test[20:]\n",
    "\n",
    "X_test_pred = model.predict(X_test_sequences)\n",
    "\n",
    "predicted_labels = X_test_pred.argmax(axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_test_original = label_encoder.inverse_transform(y_test_adjusted)\n",
    "y_pred_original = label_encoder.inverse_transform(predicted_labels)\n",
    "\n",
    "results.scores(y_test_original, y_pred_original, ('n', 'r', 'w'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing model on other mice"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test_model_on_other_mice(model, mice):\n",
    "    mouse = fspliter.get_mice(mice)\n",
    "    _, _, X_testmouse, _, _, y_testmouse = train_test_validation_split_on_day_3(mouse)\n",
    "\n",
    "    #X_test_sequences = create_sequences(X_testmouse.values, 5)\n",
    "    X_test_sequences = create_bidirectional_sequences(X_testmouse.values, 10)\n",
    "\n",
    "    y_test_adjusted = y_testmouse[20:]\n",
    "\n",
    "    X_test_pred = model.predict(X_test_sequences)\n",
    "    predicted_labels = X_test_pred.argmax(axis=1)\n",
    "    y_test_original = label_encoder.inverse_transform(y_test_adjusted)\n",
    "    y_pred_original = label_encoder.inverse_transform(predicted_labels)\n",
    "    results.scores(y_test_original, y_pred_original, ('n', 'r', 'w'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing model on same strain"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_model_on_other_mice(model, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing model on other strain"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_model_on_other_mice(model, 4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "arnn",
   "language": "python",
   "display_name": "arnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
